---
title: 线程池
updated: 2025-06-16T16:26:37
created: 2025-04-28T10:39:56
---

**线程池是为了避免频繁地创建和销毁线程地开销，以及控制并发执行地线程数量，提高系统的性能和资源利用率**
组成包括：

- **线程池管理器**：创建、管理和控制线程池。即创建、销毁、状态监控和任务调度等
- **工作队列**：存储待执行的任务。当线程池中的线程都在执行任务时，新的任务会被放入工作队列中等待执行
- **线程池线程**：实际执行任务的线程。线程池会维护一组线程；可以被重复使用

核心参数：

- 线程池的基本大小
- 最大线程数量
- 线程空闲后的存活时间
- 存放任务的阻塞队列
- 拒绝策略

#### 线程池中线程的生命周期

##### 生命周期

- **何时创建**：
- **何时存活**：keepalive 时间未到
- **何时回收**：空闲时间超过 keepalive 的非核心线程
- **异常退出**：

##### 衡量线程数和存活时间

1、**线程数**<br>
`cpu密集型`:Ncpu+1,过多线程只会增加上下文切换，不会更快<br>
`I/O密集型`:2Ncpu<br>
2、**队列与拒绝策略**<br>
`有界队列`:队列满且活跃线程小于最大线程池线程数，继续创建新线程到最大，再满就触发拒绝策略<br>
`拒绝策略`:回退到调用线程执行/丢弃<br>
3、**存活时间(keepalive)**<br>

<strong style="color:red">
先基于任务性质估算 core/max 与队列，再用压测数据定 keepAliveTime 与是否允许核心超时。把“扩容（创建更多线程） vs. 排队（延迟） vs. 拒绝（回退/丢弃）”这三件事的取舍说清楚、配清楚，线程的生命周期自然就“对了”。
</strong>

#### 工作流程

[Threadpool 类分析](onenote:项目的结构.one#Threadpool类分析&section-id={F5176EA1-7BB2-4240-B9A7-D836D78E81EC}&page-id={032643BE-06B0-46E2-BD13-19B65DAC37F1}&end&base-path=https://d.docs.live.net/E904BB69ECE1AACD/文档/WebServer)

### 线程、协程和进程的区别

#### 进程

在内存中运行，每个进程都有自己独立的一块内存空间，**一个进程可以有多个线程**
**孤儿进程**：父进程先于子进程结束，子进程被 init 进程(pid=1)接管

- 无害的系统正常现象
- 由 init 进程自动回收资源
- 不会消耗系统资源(除了正常占用的资源)
  **僵尸进程**：子进程已终止，但其退出状态未被父进程读取(wait/waitpid)
- 进程表中仍占有一个条目
- 不占用内存等资源，但占用 PID
- 大量僵尸进程会导致无法创建新进程
  **守护进程 ：**在后台运行的独立进程，通常没有控制终端、系统服务常用形式(如 httpd、sshd)
- 通常由 init 进程直接或间接启动
- 生命周期长，往往随系统启动而启动
- 脱离终端运行，不受用户登录/注销影响

#### 线程

进程中的一个执行任务，负责当前进程中程序的执行。

#### 使用 std::thread 进行多线程编程

`std::thread`是 c++11 标准库中提供的多线程编程工具。

##### 创建线程

```c++
#include<thread>

std::threadf t(threadfunc); // 创建并启动线程
```

##### 线程管理

###### join 和 detach()

```c++
#include <iostream>
#include <thread>
#include <chrono>

void worker() {
    std::this_thread::sleep_for(std::chrono::seconds(1));
    std::cout << "Worker thread finished" << std::endl;
}

int main() {
    std::thread t(worker);

    // join() - 等待线程完成
    t.join();
    std::cout << "Main thread after join" << std::endl;

    // 或者使用 detach() - 分离线程（线程在后台运行）
    std::thread t2(worker);
    t2.detach();

    // 主线程不需要等待 t2
    std::cout << "Main thread after detach" << std::endl;

    // 给detached线程一点时间完成
    std::this_thread::sleep_for(std::chrono::seconds(2));

    return 0;
}

```

##### 线程同步

###### 使用互斥锁（std::mutex)

```c++
#include <iostream>
#include <thread>
#include <mutex>
#include <vector>

std::mutex mtx;
int sharedData = 0;

void increment() {
    for (int i = 0; i < 100000; ++i) {
        std::lock_guard<std::mutex> lock(mtx);
        ++sharedData;
    }
}

int main() {
    std::thread t1(increment);
    std::thread t2(increment);

    t1.join();
    t2.join();

    std::cout << "Final value: " << sharedData << std::endl;
    return 0;
}
```

#### 协程

比线程更加轻量级的存在，一个线程可以拥有多个协程
协程不被操作系统内核所管理，完全由程序控制（在用户态执行）
**协程切换同样有上下文切换，但是开销极小，主要发生在用户态**

##### 协程适用的场景

1.  **IO 密集型**：
2.  **非 CPU 密集型**：
3.  **需要高并发连接**：

##### 不适合的场景

1.  **纯 CPU 密集型计算**：
2.  **真正并行**：

**区别**

- **根本区别**：**进程是操作系统资源分配的基本单位，线程是处理器任务调度和执行的基本单位**
- 资源开销：每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看作轻量级的进程，**同一类线程共享代码和数据空间**，每个线程都有自己独立的运行栈和程序计数器，切换开销小
- 包含关系：线程是进程的一部分
- 内存分配：同一进程的线程共享本进程的地址空间和资源，进程间的地址和资源是相互独立的
- 影响关系：一个进程崩溃后，保护模式下不会对其他进乘产生影响，但是一个线程崩溃整个进程会死掉
- 执行过程：线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，均可并发执行

### 进程间通信

1.  **管道** - 最简单、效率最差 - 本质是内核中的一个**缓存** - 进程创建一个管道后，Linux 会返回两个文件描述符，一个是写入，一个是写出，通过这两个文件描述符往管道写入或者读取 - 缺点： - 半双工通信，一条管道只能一个进程写，一个进程读，不能同时进行
    **管道的核心结构：内核缓冲区 + 文件描述符对**

- 当你调用 pipe(fd) 时，内核会执行以下操作：
  - 分配一块内存区域，作为缓冲区（通常是**页大小**，例如 4KB）；
  - 创建两个文件描述符：
    - fd\[0\]：**读端**（Read End）
    - fd\[1\]：**写端**（Write End）
  - 分别指向这个缓冲区的读写接口。
    这一机制在内核中由 pipe_inode_info、pipe_buffer、file_operations 等结构实现。

**管道缓冲区的本质：内核中的环形队列（FIFO Queue）**

- 数据写入 fd\[1\] 会被追加到内核缓冲区尾部；
- 数据从 fd\[0\] 读取时，会从缓冲区头部读取并消费；
- 如果缓冲区满，写操作会阻塞；
- 如果缓冲区空，读操作会阻塞；
- 可通过设置 O_NONBLOCK 变为非阻塞模式。

2.  **消息队列**
    - A 进程往消息队列中写入数据后可以正常返回，B 进程需要时读取，效率较高
    - 可以边发送边接收
    - 缺点：
      - 每个消息体有一个最大长度限制，并且队列包含的消息体的总长度也是有上限的
      - 消息队列通信过程存在用户态和内核态之间的数据拷贝问题
3.  **共享内存**
    - 解决了消息队列在内核态和用户态之间数据拷贝过程带来的开销。**直接分配一个共享空间，每个进程都可以访问**，具有最快的进程间通信
    - 缺点：
      - 多进程竞争同个共享资源会造成数据的错乱
4.  **信号量**
    - 确保任何时候只要一个进程访问共享空间。本质是一个整型的计数器，表示资源个数，用于实习进程间的互斥和同步
5.  **信号**
    - 对于异常的工作模式，需要用信号的方式通知进程
    - 是进程间通信机制中**唯一的异步通信机制**
6.  **socket**
    - 实现跨网络和不同主机上的进程进行通信

### 线程间竞争（通信）

多个线程**并发访问共享资源**，并且至少一个线程是写操作，不加以同步，会报错
线程并发执行，执行顺序不确定，会发生：**值被覆盖**、**读取到中间状态**、**程序崩溃或死锁**
需要使用**同步机制**保护共享资源
| **同步机制** | **说明** |
|----|----|
| **互斥锁（mutex）** | 最基本的同步方式，保证临界区代码同时只能被一个线程执行 |
| **读写锁（shared_mutex）** | 允许多个线程同时读，但写时互斥 |
| **原子变量（atomic）** | 轻量级同步方式，适合简单操作（如计数器） |
| **条件变量（condition_variable）** | 用于线程等待某个条件成立（例如生产者-消费者模型） |
| **信号量（semaphore）** | 用计数器控制访问资源的线程数，可用于计数或同步 |
| **屏障（barrier）** | 所有线程到达某点后再继续执行（如线程同步起步） |

#### 单核 CPU 多线程需要加锁吗？

单核 CPU 在**任意时刻只能执行一个线程**，但**多个线程之间仍然是并发的（通过时间片轮转实现切换）**，会导致竞态条件
**即使是单核 CPU，多线程访问共享资源仍然需要加锁**，因为操作系统线程调度可能在任意时刻打断当前线程，从而造成数据竞态或不一致。

#### 多线程不加锁的场景

**一、每个线程只操作自己的私有数据**

- 多个线程访问不同的变量或内存区域
  **二、多个线程只读同一份共享数据**
- 数据在多个线程中并发读取但不修改
  **三、使用线程局部存储**
- 每个线程有自己的副本
  **四、原子类型**
- 原子变量底层实现了无锁同步（CAS），适合简单读写
  **五、使用无锁数据结构或并发容器**
- 在内部实现线程安全

### 什么是线程安全，怎么实现线程安全

当多个线程同时访问同一个函数或对象时，**不管调度方式如何或运行时如何交替执行**，都不会出现数据竞争、状态混乱或异常行为。
**方法一：互斥锁（mutex）**

- 保证临界区同一时刻只能被一个线程执行；
- 推荐使用 std::lock_guard 自动加解锁。
  **方法二：原子变量（std::atomic）**
- 适用简单的读写或计数操作，性能高于锁
  **方法三：线程本地存储（thread_local）**
- 线程有独立副本，无需加锁
  **方法四：并发容器 / 无锁数据结构**

### 场景问题

#### 1. 假设线程池大小为 10，突然收到 10000 个任务，线程池的工作流程

- 任务分配
  - 前 10 个任务会立即由 10 个线程执行
- 任务队列填充
  - 核心线程已满，新任务会被放入任务队列
- 触发拒绝策略
  - 当队列已满且线程被占满，会触发拒绝策略
    1.  AbortPolicy（默认）：抛出 RejectedExecutionException。
    2.  **CallerRunsPolicy**：由提交任务的线程直接执行该任务（如主线程）。
    3.  **DiscardPolicy**：静默丢弃新任务。
    4.  **DiscardOldestPolicy**：丢弃队列中最旧的任务，然后重试提交。
- 任务执行完后线程回收

#### 2.除了拒绝策略，如何提高并发请求数量

1.  任务分片与批处理
    - 拆分大任务：将大任务拆分为多个小任务，分散到线程池中执行
    - 批处理：拆分为多个组，每组 100 个任务，分批处理
2.  异步非阻塞处理
    - reactor 框架，通过事件驱动模型处理高并发
      - 适用：I/O 密集型任务、减少线程等待时间
    - 协程
      - 资源占用低，无上下文切换
3.  分布式任务调度
    - 多级线程池
      - 分层处理任务，
        - 第一层：快速接收请求
        - 第二层：后台线程池异步处理实际任务
    - 分布式队列
      - 使用消息队列，多个消费者集群横向扩展
4.  资源隔离与降级
    - 线程隔离：
      - 业务线程与非业务使用独立线程池
    - 服务降级
      - 高负载时关闭非核心功能

### 3.如果在某一段时间并发量非常高，如何设计来抗住并发量

需要涵盖数据库设计、后端架构、缓存优化、并发控制、限流等操作

1.  **缓存系统 redis**缓解数据库压力
    - 热数据（商品详情、库存量、浏览量）存 redis
    - 请求先查 redis
2.  **限流与熔断**
    - 接口限流：限制 IP 每秒 10 次
    - 高并发接口使用验证机制
    - 熔断：一旦失控、自动断开
3.  **使用消息队列异步处理耗时任务**
    - 典型：下单后处理库存、发送短信、发货通知、支付回调
4.  **数据库优化：水平拆分**
    - 读写分离
    - 分库分表：按用户 ID 或订单 ID 进行分表
5.  **商品库存扣减**
    - 防止并发超卖、原子操作
