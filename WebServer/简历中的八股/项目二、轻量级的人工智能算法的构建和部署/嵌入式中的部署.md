---
title: 嵌入式中的部署
updated: 2025-06-15T13:20:42
created: 2025-06-15T13:20:30
---

背景：需要在资源有限的嵌入式平台上实现深度学习推理，用于本地化处理。

任务：将 PC 端训练得到的模型迁移到嵌入式设备，并保证基本推理功能。

行动：

- 从训练框架导出模型参数，编写解析程序，将权重固化到嵌入式存储中；

- 手工实现基础算子（卷积、激活、全连接等）在嵌入式 C 环境下的运行；

- 通过逐层测试验证推理正确性，确保与原始模型输出一致。

结果：成功在嵌入式设备上实现模型推理，完成从权重导出到设备端运行的端到端流程，为后续量化与优化奠定基础。


## 轻量级AI算法嵌入式部署项目总结（简历版本）
项目名称：基于STM32F4的轻量级AI模型端侧部署与性能优化

核心贡献： 独立负责将一款计算量16k FLOPs、参数量600+的轻量级AI算法部署至STM32F407嵌入式平台，实现低功耗、高实时的离线推理能力。

关键技术细节：

模型轻量化与固化： 对预训练模型进行量化与剪枝，最终将权重与偏置转换为const静态常量数组，固化于MCU的Flash存储器中，节省了~2.4KB的宝贵RAM空间。

内存精细化管理： 深入分析内存架构，通过预分配静态缓冲区、优化数据结构访问模式，确保了推理过程中间张量的高效存取，避免了动态内存分配的不确定性及碎片问题。

高性能算子实现： 摒弃通用库，手工实现核心算子（Conv1D, Dense, ReLU）。针对Cortex-M4内核的单精度FPU与DSP指令集进行深度优化，采用循环展开、指针偏移等手段，极致压榨硬件计算效能。

系统集成与部署： 设计了一体化烧录方案，将算法与应用程序编译为单一固件，简化了生产流程。确保了在无操作系统环境下，从硬件上电到推理完成的完整链路的可靠性与确定性。