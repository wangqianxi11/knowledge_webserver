## 动态自适应阈值（Dynamic-Adaptive Threshold, DAT）模块
该模块的核心思想是**摒弃传统的固定置信度阈值**，根据模型当前的学习状态和每个类别的特点，<b>为每个类别动态地、自适应地调整用于选择伪标签的阈值。</b>

## 实现步骤
DAT模块的策略是为每个类别c设定一个独立的阈值 $\tau_t(c)$，该阈值会随着训练轮次t和模型对该类别的学习情况（以平均置信度 $\mu_w(c)$ 衡量）而动态变化。其实现分为以下几个步骤：

### 1. 核心动态更新机制：

这是DAT最核心的公式，如论文中式(3)所示

$$
\tau_t(c) = \begin{cases}
    \tau_0(c),  & t= 0\\
    \lambda\cdot\tau_{t-1}(c) + (1-\lambda)\cdot\mu_\omega(c), & t > 0
\end{cases}
$$

- $\mu_w(c)$ (均值置信度)：当前批次中，模型对类别c预测概率的平均值（式(4)）。它反映了模型当前对类别c的整体把握程度。$\mu_w(c)$ 越高，说明模型越有把握，阈值就可以适当提高，以选取更高质量的伪标签。

- $\lambda$ (动量系数)：设置为0.99，这是一个非常高的值。这意味着阈值的更新是平滑和保守的，不会因为单个批次的变化而产生剧烈波动，保证了训练过程的稳定性。

- $\tau_0(c)$ (初始阈值)：为避免初期噪声大的伪标签误导模型，初始阈值设置得较高。文中采用每个类别c前25%高置信度像素的平均值作为初始值。这是一个“高门槛”启动策略。

这个更新机制的含义是：每个类别的阈值 $\tau_t(c)$ 是其历史阈值（$\tau_{t-1}(c)$）和当前平均置信度（$\mu_w(c)$）的加权平均。 随着模型训练得越来越好，对各类别的预测置信度会逐渐升高，从而带动阈值 $\tau_t(c)$ 也稳步上升。

### 2. 类别间自适应缩放：

仅有上述机制还不够，因为它只考虑了类别自身的历史变化，没有考虑不同类别之间的差异。例如，背景类的置信度通常远高于病灶类。如果直接用 $\mu_w(c)$ 更新，会导致背景阈值过高，而病灶阈值相对过低。

$$
\omega_c = \frac{p_{mix}^{c,max}}{max(p_{mix}^\omega)}
$$

- $p^{c,max}_{mix}$：**类别c在当前批次中的最大置信度值**。它代表了模型预测该类别的“上限”。

- $max(p^{w}_{mix})$：**所有类别中的最大置信度值**（通常是背景类的）。

- $w_c$：缩放因子。对于置信度上限高的类别（如背景），$w_c$ 接近1，阈值保持较高；对于置信度上限低的类别（如小病灶），$w_c$ 会变小，从而降低其阈值。
  
最终，阈值按下式进行缩放：

$$
\tau_t(c) = \tau_t(c)\cdot\omega_c
$$

这个缩放策略的含义是： 根据模型能力为不同类别“量身定制”阈值。对于难以学习的类别（置信度上限低），降低阈值，允许更多该类的像素被选为伪标签，**提高数据利用率**；对于容易学习的类别（置信度高），提高阈值，只选择最确信的样本，**保证伪标签质量**。

### 3. 伪标签选择与损失计算：

经过以上步骤得到每个类别的自适应阈值 $\tau_t(c)$ 后，用它来筛选伪标签并计算无监督损失 $\mathcal{L}_{DAT}$（式(7))：

其中 $(p^{c}_{mix}(k)>\tau_t(c))$ 是一个指示函数，只有当像素k属于类别c的预测概率大于该类别的动态阈值 $\tau_t(c)$ 时，该像素才会被纳入损失计算。


## 二、优势（为什么有效）
DAT模块相比固定阈值策略，具有以下显著优势：

### 1.缓解确认偏差（Confirmation Bias），尤其针对病灶：

固定阈值（如0.95）会系统性地偏向高置信度类别（如背景），而**过滤掉低置信度但可能是正确的病灶预测**。这会导致模型越来越自信于预测背景，而无法学习到病灶特征，即确认偏差。

DAT通过为病灶类别**动态降低阈值**，使得更多潜在的病灶像素能够作为伪标签参与训练，从而打破这种偏差，让模型能够更好地学习 minority classes（如病灶）。

### 2.显著提高数据利用率：

在训练初期，模型置信度普遍较低，固定阈值会抛弃大量可能正确的预测，导致可用的无标签数据很少。

DAT在训练初期自动保持较低的阈值（因为 $\mu_w(c)$ 低），允许更多像素参与训练。随着模型能力增强，阈值逐渐升高，对伪标签的质量要求变严。这实现了“课程学习”（Curriculum Learning） 的效果，在早期充分利用数据，在后期精细化学习。

### 3.缓解类不平衡（Class Imbalance）问题：

医学图像中背景和病灶像素数量极度不平衡。固定阈值会加剧这种不平衡，因为背景像素更容易被选中。

DAT的按类别独立设定阈值的策略，本质上是为不同类别提供了公平的竞争环境。小类别（病灶）由于其置信度特性，会自动获得更低的阈值，从而有更多机会被选中，有效缓解了长尾分布问题。

### 4.自适应模型状态，稳定训练：

固定阈值是“一刀切”，无法适应模型不同训练阶段的能力变化。

DAT的阈值与模型当前的置信度输出（$\mu_w(c)$）紧密绑定，是一个自我反馈和调节的过程。模型越好，阈值越高，要求越严；模型遇到困难，阈值降低，给予更多帮助。这种自适应性使得训练过程更加平滑和稳定。